
\newpage
\section{Likelihood ratio tests}
Likelihood ratio tests are  a class o tests based on the comparison of the values of the likelihood functions of two
candidate models. LRTs can be used to test hypotheses about covariance parameters or fixed effects parameters in the context
of LMEs.

The test statistic for the LRT is the difference of the log-likelihood functions, multiplied by $-2$.
The probability distribution of the test statistic is approximated by the $\chi^2$ distribution with ($\nu_{1} - \nu_{2}$) degrees of freedom, where $\nu_{1}$  and $\nu_{2}$ are the degrees of freedom of models 1 and 2 respectively.

The score function $S(\theta)$ is the derivative of the log likelihood with respect to $\theta$,

\[
S(\theta) = \frac{\partial}{\partial \theta}\emph{l}(\theta),
\]

and the maximum likelihood estimate is the solution to the score equation
\[
S(\theta) = 0.
\]
The Fisher information $I(\theta)$, which is defined as
\[
I(\theta) = - \frac{\partial^2}{\partial \theta^2}\emph{l}(\theta),
\]
give rise to the observed Fisher information ($I(\hat{\theta})$) and the expected Fisher information ($\mathcal{I}(\theta)$).

%==================================================================%
Likelihood Ratio Tests

L= - 2ln is approximately distributed as 2 under H_0 for large sample size and under the normality assumption.

The power of the likelihood ratio test may depends on specific sample size and the specific number of replications, and [Roy 2009] proposes simulation studies to examine this further.

Estimation Methods
Nested LME models, fitted by ML estimation, can be compared using the likelihood ratio test [Lehmann (1986)].
Models fitted using REML estimation can also be compared, but only if both were fitted using REML, and both have the same fixed effects specifications.

Likelihood ratio tests are generally used to test the significance of terms in the random effects structure.
Information Criteria
Additionally nested models may be compared by using the Akaike Information Criterion,(AIC) and the Bayesian Information Criterion (BIC).

When comparing the respective scores for nested models, the model with the smaller score is considered to be the preferable model.
ML / REML
[Morrell 1998]
The variance components in the LME model may be estimated by ML or REML.
Maximum Likelihood estimates do not take into account the estimation of fixed effects and so
are biased downwards.
REML estimates accounts for the presence of these nuisance parameters by maximising the linearly independent error contrasts to obtain more unbiased estimates.
Treatment of items as fixed effects
[Pinheiro Bates 2000] addresses the issue of treating items as fixed effects. Such a specification is useful only for the specific sample of items, rather than the population of items, where the interest would naturally lie.

[Pinheiro Bates 2000] advises the specification of random effects to correspond to items; treating the item effects as random deviations from the population mean.

Indeed [Roy 2009] follows this approach.
Grubb’s One Way Classification Model 
Carstensen develops a model that accords with a well-established method comparison methodology, that of Grubbs’ 1946 paper.


