
\documentclass[12pt, a4paper]{report}
\usepackage{natbib}
\usepackage{vmargin}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{framed}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\bibliographystyle{chicago}
\renewcommand{\baselinestretch}{1.1}

% left top textwidth textheight headheight % headsep footheight footskip
\setmargins{2.0cm}{2cm}{15.5 cm}{23.5cm}{0.5cm}{0cm}{1cm}{1cm}

\pagenumbering{arabic}
\begin{document}
	
	\subsection{LikelihoodRatio Tests}
	
	Conventionally LME models can be tested using Likelihood Ratio Tests, wherein a reference model is compared to a nested model.
	\begin{framed}
		\begin{verbatim}
		> Ref.Fit = lme(y ~ meth-1, data = dat,   #Symm , Symm#
		+     random = list(item=pdSymm(~ meth-1)), 
		+     weights=varIdent(form=~1|meth),
		+     correlation = corSymm(form=~1 | item/repl), 
		+     method="ML")
		\end{verbatim}
	\end{framed}
	Roy(2009) presents two nested models that specify the condition of equality as required, with a third nested model for an additional test. There three formulations share the same structure, and can be specified by making slight alterations of the code for the Reference Model.
	Nested Model (Between-Item Variability)
	\begin{framed}
		\begin{verbatim}
		> NMB.fit  = lme(y ~ meth-1, data = dat,   #CS , Symm#
		+     random = list(item=pdCompSymm(~ meth-1)),
		+     correlation = corSymm(form=~1 | item/repl), 
		+     method="ML")
		\end{verbatim}
	\end{framed}
	
	
	
	\begin{framed}
		\begin{verbatim}
		Nested Model (Within â€“item Variability)
		> NMW.fit = lme(y ~ meth-1, data = dat,   #Symm , CS# 
		+     random = list(item=pdSymm(~ meth-1)),
		+     weights=varIdent(form=~1|meth), 
		+     correlation = corCompSymm(form=~1 | item/repl), 
		+     method="ML")
		\end{verbatim}
	\end{framed}
	
	Nested Model (Overall Variability)
	Additionally there is a third nested model, that can be used to test overall variability, substantively a a joint test for between-item and within-item variability. The motivation for including such a test in the suite is not clear, although it does circumvent the need for multiple comparison procedures in certain circumstances, hence providing a simplified procedure for non-statisticians.
	
	\begin{framed}
		\begin{verbatim}
		> NMO.fit = lme(y ~ meth-1, data = dat,   #CS , CS# 
		+     random = list(item=pdCompSymm(~ meth-1)), 
		+     correlation = corCompSymm(form=~1 | item/repl), 
		+     method="ML")
		\end{verbatim}
	\end{framed}
	
	ANOVAs  for  Original Fits
	The likelihood Ratio test is very simple to implement in R. All that is required it to specify the reference model and the relevant nested mode as arguments to the command anova().
	The figure below displays the three tests described by Roy (2009).
	
	\begin{framed}
		\begin{verbatim}
		> testB    = anova(Ref.Fit,NMB.fit)                          # Between-Subject Variabilities
		> testW   = anova(Ref.Fit,NMW.fit)                        # Within-Subject Variabilities
		> testO     = anova(Ref.Fit,NMO.fit)                        # Overall Variabilities
		
		\end{verbatim}
	\end{framed}
	
	
	
	
	%-----------------------------------------------------------------------------------------------------%
	\newpage
	
	
	
\subsection{Reference Model (Ref.Fit)}
Conventionally LME models can be tested using Likelihood Ratio Tests, wherein a reference model is compared to a nested model.
\begin{framed}
	\begin{verbatim}
	> Ref.Fit = lme(y ~ meth-1, data = dat,   #Symm , Symm#
	+     random = list(item=pdSymm(~ meth-1)), 
	+     weights=varIdent(form=~1|meth),
	+     correlation = corSymm(form=~1 | item/repl), 
	+     method="ML")
	\end{verbatim}
\end{framed}


Roy(2009) presents two nested models that specify the condition of equality as required, with a third nested model for an additional test. There three formulations share the same structure, and can be specified by making slight alterations of the code for the Reference Model.

\subsection{Nested Model (Between-Item Variability)}
\begin{framed}
	\begin{verbatim}
	> NMB.fit  = lme(y ~ meth-1, data = dat,   #CS , Symm#
	+     random = list(item=pdCompSymm(~ meth-1)),
	+     correlation = corSymm(form=~1 | item/repl), 
	+     method="ML")
	\end{verbatim}
\end{framed}

\section{Testing Procedures}
Roy's methodology requires the construction of four candidate models. The first candidate model is compared to each of the three other models successively. It is the alternative model in each of the three tests, with the other three models acting as the respective null models.


The probability distribution of the test statistic can be approximated by a chi-square distribution with ($\nu_1$ - $\nu_2$) degrees of freedom, where $\nu_1$ and $\nu_2$ are the degrees of freedom of models 1 and 2 respectively.

Likelihood ratio tests are very simple to implement in \texttt{R}, simply use the 'anova()' commands. Sample output will be given for each variability test.
The likelihood ratio test is the procedure used to compare the fit of two models. For each candidate model, the `-2 log likelihood' ($M2LL$) is computed. The test statistic for each of the three hypothesis tests is the difference of the $M2LL$ for each pair of models. If the $p-$value in each of the respective tests exceed as significance level chosen by the analyst, then the null model must be rejected.

\begin{equation}
-2\mbox{ ln }\Lambda_{d} =  [ M2LL \mbox{ under }H_{0} \mbox{ model}] - [ M2LL \mbox{ under }H_{A} \mbox{ model}]
\end{equation}

These test statistics follow a chi-square distribution with the degrees of freedom computed as the difference of the LRT degrees of freedom.

\begin{equation}
\nu = [\mbox{ LRT df under }H_{0} \mbox{ model}] - [\mbox{ LRT df under }H_{A} \mbox{ model}]
\end{equation}

\newpage   
\begin{verbatim}
> anova(MCS1,MCS2)
>
>
     Model df    AIC    BIC  logLik   Test L.Ratio p-value
MCS1     1  8 4077.5 4111.3 -2030.7
MCS2     2  7 4075.6 4105.3 -2030.8 1 vs 2 0.15291  0.6958
\end{verbatim}
\end{document}
